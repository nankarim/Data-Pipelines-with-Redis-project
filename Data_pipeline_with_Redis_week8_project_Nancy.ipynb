{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install redis"
      ],
      "metadata": {
        "id": "23zqfCZTgs1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "import redis"
      ],
      "metadata": {
        "id": "qYYI3UZIgN3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redis Cloud Instance Information\n",
        "redis_host = 'redis-14735.c84.us-east-1-2.ec2.cloud.redislabs.com:14735'\n",
        "redis_port ='15487'\n",
        "redis_password ='test'"
      ],
      "metadata": {
        "id": "--PAPEPW56jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Postgres Database Information\n",
        "pg_host = '34.31.101.211'\n",
        "pg_database = 'nancy_redisproj'\n",
        "pg_user = 'nancyredis'\n",
        "pg_password = 'test'"
      ],
      "metadata": {
        "id": "Dxbx2ECo6N8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr4cL_Be65nP",
        "outputId": "79ec4286-313c-46d2-b0f1-c8186bc435ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.85.180.177"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redis Client Object\n",
        "r = redis.Redis(host='redis-14735.c84.us-east-1-2.ec2.cloud.redislabs.com:14735', port=15487, password='test', ssl=True)"
      ],
      "metadata": {
        "id": "AcSlJ70MCTwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data():\n",
        "    # Extract data from CSV file using pandas\n",
        "    data = pd.read_csv('customer_call_logs.csv')\n",
        "    \n",
        "    # Cache data in Redis for faster retrieval\n",
        "    redis_client.set('customer_call_logs', df.to_msgpack(compress='zlib'))"
      ],
      "metadata": {
        "id": "ZbvmQJk3D_ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data():\n",
        "    # Retrieve data from Redis cache\n",
        "    data = pd.read_json(redis_client.get('customer_call_logs'))\n",
        "\n",
        "    # Transform data (clean, structure, format)\n",
        "    # Clean and structure data\n",
        "    df = df.drop_duplicates()  # Remove duplicate rows\n",
        "    df['duration_minutes'] = df['duration_seconds'] / 60  # Add a new column for duration in minutes\n",
        "    df = df[['customer_id', 'call_date', 'duration_minutes', 'cost', 'destination']]  # Select relevant columns\n",
        "    \n",
        "    # Format data\n",
        "    df['call_date'] = pd.to_datetime(df['call_date'], format='%Y-%m-%d %H:%M:%S')\n",
        "    df['cost'] = df['cost'].apply(lambda x: round(x, 2))  # Round cost to 2 decimal places\n",
        "\n",
        "    return transformed_data\n"
      ],
      "metadata": {
        "id": "UCfUUzheFdtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    # Connect to Postgres database\n",
        "    conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)\n",
        "\n",
        "    # Create a cursor object\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Create a table to store the data\n",
        "    cur.execute('CREATE TABLE IF NOT EXISTS customer_call_logs (\\\n",
        "                 customer_id INT,\\\n",
        "                 call_cost_usd FLOAT,\\\n",
        "                 call_destination VARCHAR,\\\n",
        "                 call_date TIMESTAMP,\\\n",
        "                 call_duration_min FLOAT\\\n",
        "                 )')\n",
        "    "
      ],
      "metadata": {
        "id": "0-sGwkwnGj6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert the transformed data into the database\n",
        "    for i, row in transformed_data.iterrows():\n",
        "        cur.execute(f\"INSERT INTO customer_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost_usd']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})\")"
      ],
      "metadata": {
        "id": "LPBK0baE-Wdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commit the changes\n",
        "    conn.commit()"
      ],
      "metadata": {
        "id": "1KW_NCZE9p2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the cursor and connection\n",
        "    cur.close()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "K9EqPedZ9wm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_pipeline():\n",
        "    # Data pipeline function\n",
        "    extract_data()\n",
        "    transformed_data = transform_data()\n",
        "    load_data(transformed_data)"
      ],
      "metadata": {
        "id": "DhQvJESl9y63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "# Run the data pipeline function\n",
        "    data_pipeline()"
      ],
      "metadata": {
        "id": "CucHsLrW943K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Connect to Neo4j\n",
        "    driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))\n",
        "\n",
        "    # Extract data from Neo4j\n",
        "    with driver.session() as session:\n",
        "        result = session.run(neo4j_query)\n",
        "        df = pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
        "\n",
        "    # Transform data\n",
        "    df = transform_data(df)\n",
        "\n",
        "    # Connect to PostgreSQL\n",
        "    conn = psycopg2.connect(host=p_host, database=p_database, user=p_user, password=p_password)\n",
        "\n",
        "    # Load data into PostgreSQL\n",
        "    insert_data(df, conn)\n",
        "\n",
        "    # Close connections\n",
        "    driver.close()\n",
        "    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":"
      ],
      "metadata": {
        "id": "kOJRqvuJr_8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Practices**:\n",
        "\n",
        "**Caching data in Redis for faster retrieval**: This reduces the time taken to access the data from the CSV file by caching it in Redis, thereby reducing the overall execution time of the pipeline.\n",
        "\n",
        "**Using parameterized queries to prevent SQL injection attacks**: This ensures that the data being inserted into the Postgres database is sanitized, preventing SQL injection attacks that could compromise the security of the database.\n",
        "\n",
        "**Using context managers to ensure resources are properly managed**: This helps to ensure that resources such as the connection to the Postgres database are properly managed and released after use, preventing memory leaks and other issues that could affect the performance of the pipeline.\n",
        "\n",
        "**Recommendations for deployment and running the pipeline with a cloud-based provider:**\n",
        "\n",
        "**Use a cloud-based Redis service**: Hosting Redis on the cloud allows for easy scalability and reduces the management overhead of maintaining an on-premise Redis instance.\n",
        "\n",
        "**Use a managed Postgres database service**: This ensures that the database is properly managed, backed up, and monitored, reducing the risk of data loss and other issues that could affect the performance of the pipeline.\n",
        "\n",
        "**Containerize the pipeline using Docker**: Containerizing the pipeline using Docker allows for easy deployment and scaling of the pipeline, making it more resilient to changes in demand and ensuring that it can be easily deployed to multiple environments."
      ],
      "metadata": {
        "id": "N3k_-oRuYrO9"
      }
    }
  ]
}